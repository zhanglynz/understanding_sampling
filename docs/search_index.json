[
["index.html", "Understanding Survey Sampling Preface", " Understanding Survey Sampling Lingyun Zhang 2020-01-03 Preface How do you learn, or to be exact, how do you learn complex stuff? I guess that many different answers will come out, because we are all different in many aspects, such as culture background, knowledge level, and learning style etc. etc.. For myself, if I want to seriously learn some complex stuff, then I will write about it. Without doubts, Sampling is complex, and it is kind of boring, but it is important (for me, because I need it for my work, and for you the reasons must be different). So, I have to learn and re-learn sampling, and now I am writing about it. Since I live and work in New Zealand, I will use contexts and examples at there. Chapter 1 introduces preliminary concepts, such as population, target population, survey populaton, simple random sample, stratified sample, cluster sample, and systematic sample. Chapter 1 also presents some knowledge about New Zealand. Chapter 2 is about sampling design; Chapter 3 is about weighting system; Chapter 4 covers how to estimate sampling errors. Chapter 5 briefly introduces software for sampling. "],
["introduction.html", "Introduction", " Introduction Sampling is all about getting/taking a sample from a population. It is clear that a sample is just a subset of a population. At the end of day, what we are concerned about are data—population and sample both are data and they can be represented as tables. So, for a population, we can use the following table to represent/show it. Unit_ID \\(Y_1\\) \\(Y_2\\) \\(\\cdots\\) \\(Y_m\\) 1 2 \\(\\vdots\\) \\(N\\) The population shown in the above table has size \\(N\\), and we are interested in the \\(m\\) unknown variables, \\(Y_1\\, Y_2,\\ \\ldots,\\ Y_m\\). A part/portion of the above table is a sample. We make efforts to use the known sample (i.e. collected data) to get insights into the whole population—this is serious business. Sampling is challenging, because not only must we deal with mathematics but also we must cope with many practical issues, such as defining population, reducing cost (as much as we can), and non-response etc. etc.. Part I of this book is about theory, and Part II focuses on practical matters in sampling. "],
["toy-examples.html", "1 Toy Examples", " 1 Toy Examples Example 1: Simple Random Sampling The population is shown as the following table. Unit_ID \\(Y\\) 1 6 2 8 3 8 4 1 5 6 6 4 7 7 8 5 9 3 10 3 The population size \\(N=10\\). Let us choose the sample size \\(n\\) be \\(5\\). There are \\({10 \\choose 5}=252\\) possible samples—here we are talking about simple random samples (SRS). In practice, we can only have one sample, and there will always be uncertainty if we use one sample to infer the whole population. The population mean \\(\\bar{Y}=5.1\\). The distribution of all possible sample means is shown below. The mean of the distribution is \\(5.1\\), which is the same as the population mean \\(\\bar{Y}\\). So, sample mean is an unbiased estimator of the population mean. The population variance is \\[ S^2=\\frac{\\sum_{i=1}^N (Y_i - \\bar{Y})^2}{N-1}=5.43 \\] The distribution of all possible sample variances (NB: the divisor is \\(n-1\\)) is shown below. The mean of the distribution is 5.43, which is the same as the population variance. So, under simple random sampling, sample variance is an unbiased estimator of the population variance. Example 2: Systematic Sampling We use the same population as in Example 1, and we take 100,000 systematic samples of size 5. (NB: These samples are also simple random samples.) a &lt;- c(6, 8, 8, 1, 6, 4, 7, 5, 3, 3) simu_run_nbr &lt;- 100000 my_sys_sample &lt;- matrix(0, 5, simu_run_nbr) for(i in 1:simu_run_nbr) {my_sys_sample[, i] &lt;- sample(a)[1:5] } the_sample_mean &lt;- apply(my_sys_sample, 2, mean) hist(the_sample_mean, main = &quot;Histogram of sample means&quot;, xlab = &quot;y-bar&quot;) (mean(the_sample_mean)) ## [1] 5.09355 the_sample_var &lt;- apply(my_sys_sample, 2, var) hist(the_sample_var, main = &quot;Histogram of sample variances&quot;, xlab = &quot;s2&quot;) (mean(the_sample_var)) ## [1] 5.429476 "],
["sampling-design.html", "2 Sampling design 2.1 General ideas 2.2 Probability proportional to size sampling 2.3 Three theoretical principles", " 2 Sampling design 2.1 General ideas Throughout this chapter, sampling design means probability sampling design. Following (but not strictly) Tillé and Wilhelm (2017), the settings are as follows: The universe is \\({\\cal U}=\\{1, 2, \\ldots, i, \\ldots, N\\}\\). A sample \\(S\\) is a subset of \\({\\cal U}\\). We restrict that \\(S\\) cannot be empty. There are \\(2^N-1\\) possible samples. Let the set of all the possible samples be denoted by \\(\\Omega\\). A sampling design specifies a probability distribution \\(p(\\cdot)\\) over \\(\\Omega\\) such that \\[ p(S)\\ge 0\\ \\hbox{and}\\ \\sum_{S\\in \\Omega} p(S)=1. \\] Define \\[ \\pi_i = \\hbox{the probability of selecting unit}\\ i \\] and for \\(i\\neq j\\) \\[ \\pi_{ij} = \\hbox{the probability that both units}\\ i\\ \\hbox{and}\\ j\\ \\hbox{are selected in the sample.} \\] Then, \\[ \\pi_i = \\sum_{i \\in S}p(S)\\ \\hbox{and}\\ \\pi_{ij}=\\sum_{\\{i,\\ j\\}\\subset S}p(S). \\] Examples of sampling designs: simple random sampling: \\[ p(S)=\\left\\{ \\begin{array}{ll} {N \\choose n}^{-1}, &amp; \\hbox{if}\\ S\\in S_n,\\\\ 0, &amp; \\hbox{otherwise}, \\end{array} \\right. \\] where \\(S_n= \\{S\\in \\Omega|\\#S = n\\}\\) and \\(n\\) is the sample size. For this sampling design, \\[ \\pi_i = \\frac{n}{N}\\ \\hbox{and}\\ \\pi_{ij}= \\frac{n(n-1)}{N(N-1)}. \\] Strafied sampling: \\[ p(S)=\\left\\{ \\begin{array}{ll} \\prod_{h=1}^H{N_h \\choose n_h}^{-1}, &amp;\\hbox{if}\\ \\#(S\\bigcap {\\cal U}_h)=n_h\\ \\hbox{for}\\ h=1,\\ldots, H,\\\\ 0, &amp; \\hbox{otherwise}, \\end{array} \\right. \\] where the universe \\({\\cal U}\\) is partitioned into \\(H\\) strata and \\(\\# {\\cal U}_h= N_h\\) for \\(h=1, \\ldots, H\\); \\(n_h\\) is the sample size for stratum \\({\\cal U}_h\\). For this sampling design, \\[ \\pi_i = \\frac{n_h}{N_h},\\ \\hbox{if}\\ i\\in {\\cal U}_h, \\] and \\[ \\pi_{ij}=\\left\\{ \\begin{array}{ll} \\frac{n_h(n_h-1)}{N_h(N_h-1)}, &amp; \\hbox{if}\\ i, j\\in {\\cal U}_h,\\\\ \\frac{n_gn_h}{N_gN_h}, &amp;\\hbox{if}\\ i \\in {\\cal U}_g,\\ j\\in {\\cal U}_h,\\ g\\neq h. \\end{array} \\right. \\] 2.2 Probability proportional to size sampling In a sampling design, an important part is selection probabilities, which accompany the items/individuals in the population. We can distinguish two cases. Case 1: all the selection probabilities are equal. Case 2: the selection probabilities are not equal. Simple random sampling is an example of Case 1; probability proportional to size (PPS) sampling is an example of Case 2. Under PPS, the selection probability of item/individual \\(i\\) is defined as \\[\\begin{equation} \\pi_i = n \\frac{Z_i}{\\sum_{i=1}^N Z_i},\\ \\text{for}\\ i=1, \\ldots, N, \\tag{2.1} \\end{equation}\\] where \\(n\\) and \\(N\\) are the sample size and population size, respectively, \\(Z_i\\) is the size/importance of item/individual \\(i\\). It is easy to see from (2.1) that \\[\\begin{equation} \\sum_{i=1}^N \\pi_i = n. \\tag{2.2} \\end{equation}\\] Actually, (2.2) is always hold if the sample size is fixed as \\(n\\); below is a quick proof. Proof: \\[ \\sum_{i=1}^N \\pi_i= \\frac{N\\binom{N-1}{n-1}}{\\binom{N}{n}}\\times 1 =n. \\] 2.3 Three theoretical principles Tillé and Wilhelm (2017) introduce three theoretical principles for sampling design. Randomization: a) make sure there are as many samples as possible, while meeting other constraints; b) select a sample at random. Overrepresentation: unequal inclusion probabilities often result in more efficient estimates, or in other words, we should “preferentially select units where the dispersion is larger.” Restriction: avoid bad samples, e.g. using auxiliary information to make sure the estimates from a sample approximately equal the known totals. That is, “samples that either nonpractical or known to be inaccurate are avoided.” We quote the following from Tillé and Wilhelm (2017). “When auxiliary information is available, it is desired to include it in the sampling design in order to increase the precision of the estimates.” “A balanced sample is such that the estimated totals of the auxiliary variables are approximately equal to the true totals.” "],
["weighting-system.html", "3 Weighting system 3.1 General ideas about weighting 3.2 The three stages in producing final weights 3.3 Calibration", " 3 Weighting system The main reference for this chapter is Haziza and Beaumont (2017). 3.1 General ideas about weighting Since a sample is a part/portion of a population, each item/individual in the sample represents itself plus others in the population; that is, a weight \\(w_i\\) should be attached to the item/individual \\(i\\). It’s obvious that \\[w_i&gt;0\\] or sometimes \\[ w_i \\ge 1. \\] Weights are important because they are used in estimation of population parameters. Given the data, i.e. variable values and weights \\(y\\) weight \\(y_1\\) \\(w_1\\) \\(y_2\\) \\(w_2\\) \\(\\vdots\\) \\(\\vdots\\) \\(y_n\\) \\(w_n\\) we have estimates of the total and mean \\[\\begin{align} \\hat{t} &amp;= \\sum_{i=1}^n w_i y_i,\\\\ \\hat{\\bar{y}} &amp;= \\frac{\\sum_{i=1}^n w_i y_i}{\\sum_{i=1}^n w_i}. \\end{align}\\] In the literature, the estimator \\(\\hat{t}\\) is called the Horvitz-Thompson (HT) estimator. 3.2 The three stages in producing final weights Stage 1: design weights \\[ d_i = \\frac{1}{\\pi_i}, \\] where \\(\\pi_i\\) is the selection/inclusion probability for item/individual \\(i\\). Stage 2: weights adjusted for non-response. We use \\(\\tilde{d}_i\\) to denote the adjusted weight for item/individual \\(i\\). Stage 3: final weights. We use \\(w_i\\) to denote the final weight for item/individual \\(i\\). 3.3 Calibration Notation We denote a population by \\(U\\). A sample is denoted by \\(S\\). Design weights: \\(\\{d_k,\\ k\\in S\\}\\). Final weights: \\(\\{w_k,\\ k \\in S\\}\\). What does calibration mean? Roughly speaking, calibration is to adjust from the design weights \\(\\{d_i\\}\\) to final weights \\(\\{w_i\\}\\) such that \\(\\{w_i\\}\\) are as close to \\(\\{d_i\\}\\) as possible; \\(\\{w_i\\}\\) satisfy calibration constraints. We will explain the exact meanings of a. and b. shortly. Why do we do calibration? According to Haziza and Beaumont (2017): The reasons for using calibration are three-fold: to force consistency of certain survey estimates to known population quantities; to reduce nonsampling errors such as nonresponse errors and coverage errors; to improve the precision of estimates. How do we do calibration? It’s clear that calibration is an optimization problem, where the decision variables are \\(\\{w_i\\}\\). The objective function is \\[ \\sum_{k\\in S} d_k\\frac{G(w_k/d_k)}{q_k}, \\] where \\(G(\\cdot)\\) is referred as a distance function—it measures the distance between \\(\\{w_i\\}\\) and \\(\\{d_i\\}\\), “\\(q_k\\) is a scale factor indicating the importance of unit \\(k\\) in the distance calculation. In most practical situations \\(q_k\\) is set to 1.” The constraints are \\[ \\sum_{k \\in S} w_k \\mathbf x_k = \\mathbf t_{\\mathbf x}, \\] where \\[ \\mathbf x_k = (x_{1k}, \\ldots, x_{Jk}), \\] and \\[ \\mathbf t_{\\mathbf x}=(t_{x_1}, \\ldots, t_{x_J}), \\] with \\[ t_{x_j}=\\sum_{k \\in U} x_{jk}. \\] Commonly used distance functions Examples "],
["sampling-error.html", "4 Sampling error", " 4 Sampling error "],
["preliminary-concepts-and-knowledge.html", "5 Preliminary concepts and knowledge 5.1 Concepts 5.2 Knowledge about NZ 5.3 Sampling design for 2018 TK", " 5 Preliminary concepts and knowledge 5.1 Concepts 5.2 Knowledge about NZ 5.3 Sampling design for 2018 TK Target population: the people who are NZ usual residents living in private dwellings aged 15 or above Maori (ethnicity or descent) Sampling frame: it’s formed by using the 2018 Census data (i.e. individual table and dwelling table) Sampling scheme: stratified two-stage sampling. In Stage 1, we take psus—SRS, and in Stage 2, we take individuals—SRS (firstly using stratification with age being the stratification variable). For each psu, we can know which region it belongs to, if it is urban or rural, if it has high/low Maori people, and based on the information we can partition all the psus into 50 strata (NB: this is after some necessary combination is done). Sample sizes: a) how many psus to be taken in each stratum; b) how many individuals to be taken from the selected psus. Notation: \\(N:\\) population size (or total number of ssus) \\(H:\\) total number of strata \\(N_h:\\) size of stratum \\(h\\), for \\(h=1, 2,\\ldots, H\\) \\(n:\\) sample size \\(n_h:\\) sample size of stratum \\(h\\), for \\(h=1, 2,\\ldots, H\\) \\(M:\\) number of psus \\(M_h:\\) number of psus in stratum \\(h\\), for \\(h=1, 2,\\ldots, H\\) \\(m_h:\\) number of psus to be taken from stratum \\(h\\), for \\(h=1, 2,\\ldots, H\\) \\(n_{ih}:\\) \\(n_h\\) is split into \\(n_{1h}\\), \\(n_{2h}\\) and \\(n_3h\\) in stage 2, where \\(i\\) indicates age group. Step 1: \\(n\\longrightarrow \\{n_1, n_2, \\ldots, n_H\\}\\), for example \\[ n_h = \\text{ceiling}\\left(\\frac{nN_h}{\\sum_{h=1}^H N_h}\\right). \\] Step 2: find \\(m_h\\), for example \\[ m_h = \\text{ceiling}\\left(\\frac{n_h}{\\frac{N_h}{M_h}}\\right). \\] Note that \\(\\frac{N_h}{M_h}\\) is average size of psus in stratum \\(h\\). Step 3: \\(n_h\\longrightarrow \\{n_{1h}, n_{2h}, n_{3h}\\}\\), for example \\[ n_{ih} = n_h\\times f_i, \\] where \\(f_i\\) is sampling fraction for age group \\(i\\) (e.g. \\(f_1=f_2=0.35,\\ f_3=0.3\\).) "],
["software.html", "6 Software", " 6 Software "],
["references.html", "References", " References Haziza, D. and Beaumont, J. (2017). Construction of Weights in Surveys: A Review. Statistical Science, Vol. 32, pp. 206-226. Tillé, Y. and Wilhelm, M. (2017). Probability Sampling Design: Principles for Choice of Design and Balancing. Statistical Science, Vol. 32, pp. 176-189. "]
]
